# Pipeline Architecture Documentation

## üìã Table of Contents
1. [System Overview](#system-overview)
2. [Pipeline Modes](#pipeline-modes)
3. [Component Architecture](#component-architecture)
4. [Data Flow](#data-flow)
5. [Performance Optimization](#performance-optimization)

---

## System Overview

This detection system is designed for **Orange Pi RV 2** with 4GB RAM, optimized for real-time person and face detection using ONNX models.

### Key Features
- ‚úÖ Dual-mode pipeline (Sequential & Parallel)
- ‚úÖ ONNX model support with CPU optimization
- ‚úÖ Fallback detectors (HOG, Haar Cascade)
- ‚úÖ Memory-efficient processing
- ‚úÖ Comprehensive metrics tracking
- ‚úÖ Support for images and videos

### System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Main Entry Point                      ‚îÇ
‚îÇ                         (main.py)                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Pipeline Factory                          ‚îÇ
‚îÇ                 (create_pipeline())                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                               ‚îÇ
        ‚ñº                               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Sequential      ‚îÇ          ‚îÇ   Parallel       ‚îÇ
‚îÇ  Pipeline        ‚îÇ          ‚îÇ   Pipeline       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                             ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                       ‚îÇ
        ‚ñº                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Person     ‚îÇ        ‚îÇ    Face     ‚îÇ
‚îÇ   Detector   ‚îÇ        ‚îÇ   Detector  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                       ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚ñº
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ   Metrics    ‚îÇ
            ‚îÇ   Tracker    ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Pipeline Modes

### 1. Sequential Pipeline

**Workflow:** Person Detection ‚Üí Face Detection (on person crops)

```
Input Image
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Person Detector ‚îÇ  ‚Üê Detect all persons in full image
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
   [Person Crops]
         ‚îÇ
         ‚îú‚îÄ‚Üí Person 1 Crop ‚Üí ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                    ‚îÇ Face Detector  ‚îÇ
         ‚îú‚îÄ‚Üí Person 2 Crop ‚Üí ‚îÇ  (on crop)     ‚îÇ
         ‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îî‚îÄ‚Üí Person N Crop ‚Üí       ‚îÇ
                                   ‚ñº
                            [Face Detections]
```

**Advantages:**
- ‚úÖ Better accuracy (faces detected in context)
- ‚úÖ Faster face detection (smaller search area)
- ‚úÖ Associates faces with specific persons
- ‚úÖ Lower memory usage

**Use Cases:**
- Crowded scenes
- Multiple persons per frame
- When person-face association is needed

### 2. Parallel Pipeline

**Workflow:** Person Detection || Face Detection (independent)

```
Input Image
    ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ                 ‚îÇ                 ‚îÇ
    ‚ñº                 ‚ñº                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Person  ‚îÇ    ‚îÇ  Face   ‚îÇ    ‚îÇ Metrics ‚îÇ
‚îÇDetector ‚îÇ    ‚îÇDetector ‚îÇ    ‚îÇ Tracker ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ              ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ
            ‚ñº
    [Combined Results]
```

**Advantages:**
- ‚úÖ Faster processing (parallel execution)
- ‚úÖ Independent detections
- ‚úÖ Good for sparse scenes

**Use Cases:**
- Single person scenarios
- When speed is critical
- When faces might be outside person boxes

---

## Component Architecture

### 1. Detector Components

#### BaseDetector (Abstract)
```python
class BaseDetector:
    - model_path: str
    - confidence_threshold: float
    - model: ONNXRuntime Session
    
    + load_model()
    + detect(image) ‚Üí List[Detection]
```

#### PersonDetector
- **Primary:** ONNX model (YOLO/NanoDet/etc.)
- **Fallback:** HOG + SVM (OpenCV)
- **Input:** Full image (640x640)
- **Output:** Person bounding boxes

```python
PersonDetector:
    + _detect_onnx(image) ‚Üí List[Detection]
    + _detect_hog(image) ‚Üí List[Detection]
```

#### FaceDetector
- **Primary:** ONNX model (YuNet/RetinaFace/etc.)
- **Fallback:** Haar Cascade (OpenCV)
- **Input:** Person crop or full image
- **Output:** Face bounding boxes

```python
FaceDetector:
    + _detect_onnx(image) ‚Üí List[Detection]
    + _detect_cascade(image) ‚Üí List[Detection]
```

### 2. Pipeline Components

#### ProcessingPipeline (Abstract)
```python
class ProcessingPipeline:
    - person_detector: PersonDetector
    - face_detector: FaceDetector
    - metrics_tracker: MetricsTracker
    
    + process_image(image, output_prefix) ‚Üí (person_count, face_count)
    + process_video(video_path, output_prefix)
```

#### SequentialPipeline
```python
SequentialPipeline(ProcessingPipeline):
    + process_image():
        1. Detect persons in full image
        2. For each person crop:
            a. Detect faces
            b. Save crops
            c. Track metrics
```

#### ParallelPipeline
```python
ParallelPipeline(ProcessingPipeline):
    + process_image():
        1. ThreadPoolExecutor (2 threads)
        2. Thread 1: Person detection
        3. Thread 2: Face detection
        4. Merge results
```

### 3. Metrics Components

#### MetricsTracker
```python
MetricsTracker:
    - fps_values: List[float]
    - accuracy_values: List[float]
    - person_processing_times: List[float]
    
    + start_processing()
    + end_processing()
    + add_frame_metrics(fps, accuracy, time)
    + get_summary() ‚Üí Dict
    + print_summary()
    + save_to_file(path)
```

---

## Data Flow

### Sequential Pipeline Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Input Image ‚îÇ
‚îÇ  (HxWx3)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Resize if needed    ‚îÇ  MAX_WIDTH=640, MAX_HEIGHT=480
‚îÇ  (Memory opt)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Person Detection    ‚îÇ
‚îÇ  - Preprocess        ‚îÇ  ‚ë† RGB, Normalize, Transpose
‚îÇ  - ONNX Inference    ‚îÇ  ‚ë° model.run(input)
‚îÇ  - NMS               ‚îÇ  ‚ë¢ Non-max suppression
‚îÇ  - Threshold filter  ‚îÇ  ‚ë£ confidence >= 0.5
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
   [Person_1] [Person_2] ... [Person_N]
       ‚îÇ
       ‚îú‚îÄ‚Üí ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ   ‚îÇ Crop Person ROI      ‚îÇ
       ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ          ‚îÇ
       ‚îÇ          ‚ñº
       ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ   ‚îÇ  Face Detection      ‚îÇ
       ‚îÇ   ‚îÇ  (on person crop)    ‚îÇ
       ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ          ‚îÇ
       ‚îÇ          ‚ñº
       ‚îÇ      [Face_1] [Face_2]
       ‚îÇ          ‚îÇ
       ‚îÇ          ‚ñº
       ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ   ‚îÇ Save Crops           ‚îÇ
       ‚îÇ   ‚îÇ - person_0.jpg       ‚îÇ
       ‚îÇ   ‚îÇ - face_0_0.jpg       ‚îÇ
       ‚îÇ   ‚îÇ - face_0_1.jpg       ‚îÇ
       ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îî‚îÄ‚Üí (Repeat for each person)
              ‚îÇ
              ‚ñº
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ  Metrics Tracking    ‚îÇ
       ‚îÇ  - FPS calculation   ‚îÇ
       ‚îÇ  - Processing time   ‚îÇ
       ‚îÇ  - Accuracy metrics  ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Parallel Pipeline Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Input Image ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ                 ‚îÇ                 ‚îÇ
       ‚ñº                 ‚ñº                 ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ   Thread 1   ‚îÇ  ‚îÇ   Thread 2   ‚îÇ        ‚îÇ
‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ        ‚îÇ
‚îÇ   Person     ‚îÇ  ‚îÇ    Face      ‚îÇ        ‚îÇ
‚îÇ  Detection   ‚îÇ  ‚îÇ  Detection   ‚îÇ        ‚îÇ
‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ        ‚îÇ
‚îÇ [Person_1]   ‚îÇ  ‚îÇ  [Face_1]    ‚îÇ        ‚îÇ
‚îÇ [Person_2]   ‚îÇ  ‚îÇ  [Face_2]    ‚îÇ        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
       ‚îÇ                 ‚îÇ                ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ
                ‚îÇ                         ‚îÇ
                ‚ñº                         ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ Save Results ‚îÇ        ‚îÇ   Metrics    ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Performance Optimization

### 1. Memory Optimization

**Input Resizing:**
```python
MAX_INPUT_WIDTH = 640
MAX_INPUT_HEIGHT = 480

if w > MAX_WIDTH or h > MAX_HEIGHT:
    scale = min(MAX_WIDTH/w, MAX_HEIGHT/h)
    image = cv2.resize(image, (new_w, new_h))
```

**Model Input Size:**
- Person detector: 640x640
- Face detector: 320x320

### 2. CPU Optimization

**ONNX Runtime Settings:**
```python
providers=['CPUExecutionProvider']  # CPU-only for Orange Pi
```

**Threading:**
```python
MAX_THREADS = 2  # Limited for 4GB RAM
ThreadPoolExecutor(max_workers=MAX_THREADS)
```

### 3. Processing Optimization

**Batch Processing:** Disabled (memory constraint)

**NMS (Non-Maximum Suppression):**
```python
cv2.dnn.NMSBoxes(boxes, scores, score_threshold, nms_threshold)
```

**Early Stopping:**
```python
if confidence < threshold:
    continue  # Skip low-confidence detections
```

### 4. Expected Performance

| Configuration | FPS (Sequential) | FPS (Parallel) | Memory Usage |
|--------------|------------------|----------------|--------------|
| 640x480 Image | 2-5 FPS | 3-7 FPS | ~800MB |
| Video (640x480) | 1-3 FPS | 2-5 FPS | ~1.2GB |
| Multiple Persons | 0.5-2 FPS | 1-3 FPS | ~1.5GB |

---

## Configuration Parameters

### Detection Thresholds
```python
PERSON_CONFIDENCE_THRESHOLD = 0.5
FACE_CONFIDENCE_THRESHOLD = 0.5
```

### Pipeline Selection
```python
DEFAULT_PIPELINE = "sequential"  # or "parallel"
```

### Thread Configuration
```python
USE_THREADING = True
MAX_THREADS = 2
```

### Output Settings
```python
SAVE_CROPPED_IMAGES = True
SAVE_ANNOTATED_OUTPUT = True
SAVE_METRICS_TXT = True
```

---

## Error Handling & Fallbacks

### Model Loading Failure
```
ONNX Model Load Failed
        ‚Üì
Use Fallback Detector
        ‚Üì
Person: HOG + SVM
Face: Haar Cascade
```

### Processing Errors
```python
try:
    # Process with ONNX
except Exception:
    # Fallback to OpenCV detectors
```

### Memory Errors
```python
# Automatic input resizing
# Limited threading (MAX_THREADS=2)
# No batch processing
```

---

## Extension Points

### Adding New Models
1. Place ONNX model in `models/` folder
2. Update `config.py`:
   ```python
   PERSON_MODEL_PATH = "models/new_model.onnx"
   ```
3. Run with `--person-model` flag

### Custom Pipeline
1. Inherit from `ProcessingPipeline`
2. Implement `process_image()` method
3. Register in `create_pipeline()` factory

### Custom Metrics
1. Extend `MetricsTracker` class
2. Add custom metric collection
3. Update summary generation

---

## Debugging & Monitoring

### Log Files
```
logs/
‚îú‚îÄ‚îÄ {input_name}_summary.txt
‚îú‚îÄ‚îÄ person_detection_metrics.log
‚îî‚îÄ‚îÄ face_detection_metrics.log
```

### Output Files
```
output/
‚îú‚îÄ‚îÄ {input_name}_person_0.jpg
‚îú‚îÄ‚îÄ {input_name}_person_1.jpg
‚îú‚îÄ‚îÄ {input_name}_face_0_0.jpg
‚îî‚îÄ‚îÄ {input_name}_annotated.jpg
```

### Metrics Displayed
- Total processing time
- FPS (min/max/avg)
- Detection accuracy
- Per-person processing time

---

## Best Practices

### For Sequential Pipeline
‚úÖ Use when: Multiple persons in scene
‚úÖ Set: Lower person threshold (0.3-0.4)
‚úÖ Optimize: Face detection on crops

### For Parallel Pipeline
‚úÖ Use when: Single person scenarios
‚úÖ Set: Higher thresholds (0.5-0.7)
‚úÖ Optimize: Both detectors independently

### Memory Management
‚úÖ Resize large inputs (>640x480)
‚úÖ Limit concurrent threads (MAX_THREADS=2)
‚úÖ Clear crops after processing

### Model Selection
‚úÖ Lightweight models: YuNet, NanoDet, UltraFace
‚úÖ Quantized models: INT8 for faster inference
‚úÖ Test fallback: Ensure HOG/Cascade work

---

## Conclusion

This pipeline architecture provides:
- üöÄ **Flexibility:** Two processing modes
- ‚ö° **Performance:** Optimized for Orange Pi
- üõ°Ô∏è **Reliability:** Fallback detectors
- üìä **Monitoring:** Comprehensive metrics
- üîß **Extensibility:** Easy to customize

For usage instructions, see [USER_GUIDE.md](USER_GUIDE.md)
